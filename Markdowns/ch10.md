# Intermediate 10 : 과제 : 구글 뉴스 
***
이번에는 [구글 뉴스](https://news.google.com/topstories?hl=ko&gl=KR&ceid=KR:ko)에서 뉴스를 검색한 결과에 대해 기사들을 가져와 보겠습니다.제가 코로나를
검색하면 url이 다음과 같이 나오는것을 알 수 있습니다.
~~~
https://news.google.com/search?q=%EC%BD%94%EB%A1%9C%EB%82%98&hl=ko&gl=KR&ceid=KR%3Ako
~~~
이 글에서는 인코딩이 되어 보이겠지만, search?q="코로나"로 검색이 될 것입니다. 자 이제 검색하고자 하는 키워드를 각자 검색하고, 개발자 도구를 연 후 아래와 같이 뉴스들이 담긴 main태그를 찾아봅시다
  
![image](https://user-images.githubusercontent.com/45956041/147619647-b7aef32c-471c-40d9-92ba-ebfca6ae8dca.png)

그리고 잘 보면 이 main태그를 기준으로 main > c > div 레이아웃 내부에 div태그들로 뉴스들이 존재하는것을 볼 수 있습니다. 그러면 뉴스들을 가져오려면 div태그들을 각각 분석해 봐야겠죠?
  
![image](https://user-images.githubusercontent.com/45956041/147619162-103a5707-ad50-4b0d-bb23-5b6ddac48d9b.png)

이번시간에는 앞에서 배웠던 내용을 가지고 최대한 코드를 작성해 보는 시간으로 하겠습니다. 각자 자신이 검색한 주제에 대해서 뉴스의 제목과 기사의 URL링크를 JSON파일로 저장해보는 과제를 주도록 하겠습니다.
약간의 힌트를 드리자면, 모든 div태그의 구조가 동일하지 않을 수 도 있습니다. 그렇기 때문에 NoneType관련된 Attribute Error가 날 수 도 있습니다. 이 부분은 예외처리로 건너 뛰어줄 수 있습니다.
이 외 모르는 것이 있다면 스스로 검색을 통해 찾아보도록 합시다. 제가 작성한 코드는 아래와 같으며 코드와 결과는 이 [링크](https://github.com/J-hoplin1/Dummy-Codies/tree/master/usefulpython/ch10)에서 보실수 있습니다.  

```python3
import requests,json
from bs4 import BeautifulSoup
from requests.api import head
from urllib.parse import quote_plus


topic = input("검색할 주제 입력하기 >> ")

headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}
url = f"https://news.google.com/search?q={quote_plus(topic)}=ko&gl=KR&ceid=KR%3Ako"
resp = requests.get(url,headers=headers)
html = BeautifulSoup(resp.text,'html.parser')
find_news_one_layout = html.find('main', attrs={'class' : 'HKt8rc'}).find('div',attrs={'class' : "lBwEZb BL5WZb xP6mwf"}).find_all('div')

news = dict()

replace_str = 'https://news.google.com'
for j,i in enumerate(find_news_one_layout,start=1):
    try:
        news_hyperlink = i.find('a').get('href') # ./article/ 형식으로 나오므로 형태 변환을 해주어야한다.
        news_title = i.find('div',attrs={'class' : 'xrnccd'}).find('article').find('h3')
        news_title = news_title.text
        news[f"News {j}"] = {
            "title" : news_title,
            "link" : f"{replace_str}{news_hyperlink[1:]}"
        }
    except AttributeError as e:
        pass

with open(f'GoogleNewsScrape_{topic}.json','w') as f:
    json.dump(news,f,indent=4,ensure_ascii=False)

```
